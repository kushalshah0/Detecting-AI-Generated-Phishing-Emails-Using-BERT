{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLI5KF8FN5q8yd31B0mfQj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kushalshah0/Detecting-AI-Generated-Phishing-Emails-Using-BERT/blob/main/ai_phishing_email_detection_FastAPI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhFEWqxz45jZ",
        "outputId": "33cb31d0-e3f1-4a4b-8c31-a85b6b08f5cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@title Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Dependencies\n",
        "!pip install fastapi uvicorn pyngrok transformers torch tensorflow pickle-mixin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLhW16zv6odD",
        "outputId": "1da3d323-6693-47e5-e837-c6bdb3b4e342"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (0.123.10)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.12/dist-packages (0.40.0)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.5.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Collecting pickle-mixin\n",
            "  Downloading pickle-mixin-1.0.2.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: starlette<0.51.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.50.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from fastapi) (2.12.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (4.15.0)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.0.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (8.3.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.12.19)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.51.0,>=0.40.0->fastapi) (4.12.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading pyngrok-7.5.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pickle-mixin\n",
            "  Building wheel for pickle-mixin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pickle-mixin: filename=pickle_mixin-1.0.2-py3-none-any.whl size=5988 sha256=57e92439568facad75a762d35a30471ce0f32a98464449282229922ac573d1ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/e2/5c/da8f96a08c63469bc8b10e206cd4c78e8886d8acb8699f84c2\n",
            "Successfully built pickle-mixin\n",
            "Installing collected packages: pickle-mixin, pyngrok\n",
            "Successfully installed pickle-mixin-1.0.2 pyngrok-7.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Verify model paths\n",
        "import os\n",
        "\n",
        "SAMPLE_NAME = \"sample1\"\n",
        "\n",
        "BASE_PATH = f\"/content/drive/MyDrive/Detect_AI_Phishing_Project/{SAMPLE_NAME}\"\n",
        "\n",
        "paths = {\n",
        "    \"LSTM\": f\"{BASE_PATH}/lstm_model.pt\",\n",
        "    \"GRU\": f\"{BASE_PATH}/gru_model.pt\",\n",
        "    \"BERT\": f\"{BASE_PATH}/bert/final_model\",\n",
        "    \"Tokenizer\": f\"{BASE_PATH}/rnn_tokenizer.pkl\"\n",
        "}\n",
        "\n",
        "for k, v in paths.items():\n",
        "    print(k, \"✅\" if os.path.exists(v) else \"❌\", v)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6gU6DBw6rSJ",
        "outputId": "949d751c-8d0c-42b9-b82b-09bd44b487f4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM ✅ /content/drive/MyDrive/Detect_AI_Phishing_Project/sample1/lstm_model.pt\n",
            "GRU ✅ /content/drive/MyDrive/Detect_AI_Phishing_Project/sample1/gru_model.pt\n",
            "BERT ✅ /content/drive/MyDrive/Detect_AI_Phishing_Project/sample1/bert/final_model\n",
            "Tokenizer ✅ /content/drive/MyDrive/Detect_AI_Phishing_Project/sample1/rnn_tokenizer.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create FastAPI project structure\n",
        "import os\n",
        "\n",
        "API_DIR = \"/content/api\"\n",
        "os.makedirs(API_DIR, exist_ok=True)\n",
        "\n",
        "files = [\"main.py\", \"models.py\", \"schemas.py\"]\n",
        "for f in files:\n",
        "    with open(os.path.join(API_DIR, f), \"w\") as fp:\n",
        "        fp.write(\"\")\n",
        "\n",
        "print(\"FastAPI files created:\", files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaUNNnmV6vti",
        "outputId": "e69efe04-5883-4328-b4b4-1d1f295fa87d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastAPI files created: ['main.py', 'models.py', 'schemas.py']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Write schemas.py\n",
        "%%writefile /content/api/schemas.py\n",
        "from pydantic import BaseModel\n",
        "\n",
        "class EmailRequest(BaseModel):\n",
        "    text: str\n",
        "    model: str  # bert | lstm | gru\n",
        "\n",
        "class PredictionResponse(BaseModel):\n",
        "    model: str\n",
        "    prediction: str\n",
        "    confidence: float"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUp7M0FL69HX",
        "outputId": "eb5afc0d-a65c-4cf2-d495-f37fb510d450"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/api/schemas.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fe90910",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "100017ac-e18c-4671-b5b8-99b0802a4157"
      },
      "source": [
        "#@title Write models.py\n",
        "%%writefile /content/api/models.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pickle\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "SAMPLE_NAME = \"sample1\"\n",
        "BASE_PATH = f\"/content/drive/MyDrive/Detect_AI_Phishing_Project/{SAMPLE_NAME}\"\n",
        "DEVICE = torch.device(\"cpu\")\n",
        "\n",
        "# Define LSTM Model Architecture (assuming a basic setup)\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, text):\n",
        "        embedded = self.embedding(text)\n",
        "        _, (hidden, _) = self.lstm(embedded)\n",
        "        return self.fc(hidden.squeeze(0))\n",
        "\n",
        "# Define GRU Model Architecture (assuming a basic setup)\n",
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, text):\n",
        "        embedded = self.embedding(text)\n",
        "        _, hidden = self.gru(embedded)\n",
        "        return self.fc(hidden.squeeze(0))\n",
        "\n",
        "# LOAD TOKENIZER\n",
        "with open(f\"{BASE_PATH}/rnn_tokenizer.pkl\", \"rb\") as f:\n",
        "    rnn_tokenizer = pickle.load(f)\n",
        "\n",
        "MAX_LEN = 200\n",
        "# Corrected model parameters based on checkpoint (from error message)\n",
        "MODEL_VOCAB_SIZE = 20000    # As indicated by embedding.weight shape in error\n",
        "EMBEDDING_DIM = 128         # As indicated by embedding.weight shape in error\n",
        "HIDDEN_DIM = 128            # As indicated by lstm.weight_ih_l0 shape in error\n",
        "OUTPUT_DIM = 1              # Binary classification\n",
        "\n",
        "# LOAD LSTM\n",
        "lstm_model = LSTMModel(MODEL_VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM).to(DEVICE)\n",
        "lstm_model.load_state_dict(torch.load(f\"{BASE_PATH}/lstm_model.pt\", map_location=DEVICE))\n",
        "lstm_model.eval()\n",
        "\n",
        "# LOAD GRU\n",
        "gru_model = GRUModel(MODEL_VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM).to(DEVICE)\n",
        "gru_model.load_state_dict(torch.load(f\"{BASE_PATH}/gru_model.pt\", map_location=DEVICE))\n",
        "gru_model.eval()\n",
        "\n",
        "# LOAD BERT\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(\n",
        "    f\"{BASE_PATH}/bert/final_model\"\n",
        ")\n",
        "bert_model = BertForSequenceClassification.from_pretrained(\n",
        "    f\"{BASE_PATH}/bert/final_model\"\n",
        ").to(DEVICE)\n",
        "bert_model.eval()\n",
        "\n",
        "# HELPERS\n",
        "def preprocess_rnn(text):\n",
        "    seq = rnn_tokenizer.texts_to_sequences([text])\n",
        "    # Map token IDs >= MODEL_VOCAB_SIZE to 0 (assuming 0 is OOV/padding)\n",
        "    processed_seq = [[token_id if token_id < MODEL_VOCAB_SIZE else 0 for token_id in s] for s in seq]\n",
        "\n",
        "    padded = np.zeros((1, MAX_LEN))\n",
        "    # Ensure sequence is not longer than MAX_LEN\n",
        "    padded[0, :min(MAX_LEN, len(processed_seq[0]))] = processed_seq[0][:MAX_LEN]\n",
        "    return torch.tensor(padded, dtype=torch.long)\n",
        "\n",
        "def predict_rnn(model, text):\n",
        "    with torch.no_grad():\n",
        "        x = preprocess_rnn(text)\n",
        "        output = model(x)\n",
        "        prob = torch.sigmoid(output).item()\n",
        "        label = \"Phishing\" if prob >= 0.5 else \"Legitimate\"\n",
        "        confidence = prob if prob >= 0.5 else 1 - prob\n",
        "        return label, confidence\n",
        "\n",
        "def predict_bert(text):\n",
        "    inputs = bert_tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=512\n",
        "    ).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        outputs = bert_model(**inputs)\n",
        "        probs = torch.softmax(outputs.logits, dim=1)\n",
        "        conf, pred = torch.max(probs, dim=1)\n",
        "        label = \"Phishing\" if pred.item() == 1 else \"Legitimate\"\n",
        "        return label, conf.item()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/api/models.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Write main.py\n",
        "%%writefile /content/api/main.py\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from schemas import EmailRequest, PredictionResponse\n",
        "from models import predict_rnn, predict_bert, lstm_model, gru_model\n",
        "\n",
        "app = FastAPI(\n",
        "    title=\"AI-Generated Phishing Detection API\",\n",
        "    version=\"1.0\"\n",
        ")\n",
        "\n",
        "@app.post(\"/predict\", response_model=PredictionResponse)\n",
        "def predict(request: EmailRequest):\n",
        "    text = request.text\n",
        "    model_name = request.model.lower()\n",
        "\n",
        "    if model_name == \"bert\":\n",
        "        label, confidence = predict_bert(text)\n",
        "\n",
        "    elif model_name == \"lstm\":\n",
        "        label, confidence = predict_rnn(lstm_model, text)\n",
        "\n",
        "    elif model_name == \"gru\":\n",
        "        label, confidence = predict_rnn(gru_model, text)\n",
        "\n",
        "    else:\n",
        "        raise HTTPException(\n",
        "            status_code=400,\n",
        "            detail=\"Invalid model. Choose from: bert, lstm, gru\"\n",
        "        )\n",
        "\n",
        "    return PredictionResponse(\n",
        "        model=model_name,\n",
        "        prediction=label,\n",
        "        confidence=round(confidence, 4)\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2emq9sJ-7Nig",
        "outputId": "ac7bbc9e-e044-4521-fa16-74fd4b3f0b50"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/api/main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b269a6c",
        "outputId": "031df31f-5049-4a27-f9f4-a757c5fdd1a0"
      },
      "source": [
        "#@title Run FastAPI\n",
        "# Kill any processes running on port 8000 or any uvicorn process\n",
        "!pkill -f uvicorn || true\n",
        "!fuser -k 8000/tcp || true\n",
        "\n",
        "%cd /content/api\n",
        "!nohup uvicorn main:app --host 0.0.0.0 --port 8000 &"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n",
            "/content/api\n",
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "994520c3",
        "outputId": "f81041c3-745c-4581-88fe-015f0872d479"
      },
      "source": [
        "#@title Display FastAPI Server Logs\n",
        "!cat nohup.out"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-20 15:33:05.256674: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2026-01-20 15:33:05.275976: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2026-01-20 15:33:05.304939: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768923185.362567    8465 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768923185.372987    8465 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768923185.409986    8465 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768923185.410039    8465 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768923185.410042    8465 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768923185.410044    8465 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-20 15:33:05.417026: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/uvicorn\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/click/core.py\", line 1485, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/click/core.py\", line 1406, in main\n",
            "    rv = self.invoke(ctx)\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/click/core.py\", line 1269, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/click/core.py\", line 824, in invoke\n",
            "    return callback(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/main.py\", line 424, in main\n",
            "    run(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/main.py\", line 594, in run\n",
            "    server.run()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 67, in run\n",
            "    return asyncio_run(self.serve(sockets=sockets), loop_factory=self.config.get_loop_factory())\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/runners.py\", line 195, in run\n",
            "    return runner.run(main)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/runners.py\", line 118, in run\n",
            "    return self._loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"uvloop/loop.pyx\", line 1518, in uvloop.loop.Loop.run_until_complete\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 71, in serve\n",
            "    await self._serve(sockets)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 78, in _serve\n",
            "    config.load()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/config.py\", line 439, in load\n",
            "    self.loaded_app = import_from_string(self.app)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/importer.py\", line 19, in import_from_string\n",
            "    module = importlib.import_module(module_str)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 999, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
            "  File \"/content/api/main.py\", line 3, in <module>\n",
            "    from models import predict_rnn, predict_bert, lstm_model, gru_model\n",
            "  File \"/content/api/models.py\", line 6, in <module>\n",
            "    BASE_PATH = f\"/content/drive/MyDrive/Detect_AI_Phishing_Project/{SAMPLE_NAME}\"\n",
            "                                                                     ^^^^^^^^^^^\n",
            "NameError: name 'SAMPLE_NAME' is not defined\n",
            "2026-01-20 15:35:14.608018: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2026-01-20 15:35:14.612802: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2026-01-20 15:35:14.626095: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768923314.648244    9034 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768923314.654864    9034 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768923314.671806    9034 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768923314.671849    9034 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768923314.671853    9034 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768923314.671856    9034 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-20 15:35:14.676961: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/uvicorn\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/click/core.py\", line 1485, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/click/core.py\", line 1406, in main\n",
            "    rv = self.invoke(ctx)\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/click/core.py\", line 1269, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/click/core.py\", line 824, in invoke\n",
            "    return callback(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/main.py\", line 424, in main\n",
            "    run(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/main.py\", line 594, in run\n",
            "    server.run()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 67, in run\n",
            "    return asyncio_run(self.serve(sockets=sockets), loop_factory=self.config.get_loop_factory())\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/runners.py\", line 195, in run\n",
            "    return runner.run(main)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/runners.py\", line 118, in run\n",
            "    return self._loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"uvloop/loop.pyx\", line 1518, in uvloop.loop.Loop.run_until_complete\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 71, in serve\n",
            "    await self._serve(sockets)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 78, in _serve\n",
            "    config.load()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/config.py\", line 439, in load\n",
            "    self.loaded_app = import_from_string(self.app)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/importer.py\", line 19, in import_from_string\n",
            "    module = importlib.import_module(module_str)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 999, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
            "  File \"/content/api/main.py\", line 3, in <module>\n",
            "    from models import predict_rnn, predict_bert, lstm_model, gru_model\n",
            "  File \"/content/api/models.py\", line 18, in <module>\n",
            "    lstm_model.eval()\n",
            "    ^^^^^^^^^^^^^^^\n",
            "AttributeError: 'collections.OrderedDict' object has no attribute 'eval'\n",
            "2026-01-20 15:36:59.597363: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2026-01-20 15:36:59.603867: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2026-01-20 15:36:59.623812: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768923419.658664    9474 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768923419.675653    9474 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768923419.725531    9474 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768923419.725582    9474 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768923419.725588    9474 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768923419.725593    9474 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-20 15:36:59.733281: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2026-01-20 15:37:01.501864: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2026-01-20 15:37:01.514777: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2026-01-20 15:37:01.541933: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768923421.590809    9485 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768923421.601185    9485 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768923421.635169    9485 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768923421.637271    9485 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768923421.637279    9485 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768923421.637283    9485 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-20 15:37:01.653490: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/uvicorn\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/click/core.py\", line 1485, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/click/core.py\", line 1406, in main\n",
            "    rv = self.invoke(ctx)\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/click/core.py\", line 1269, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/click/core.py\", line 824, in invoke\n",
            "    return callback(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/main.py\", line 424, in main\n",
            "    run(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/main.py\", line 594, in run\n",
            "    server.run()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 67, in run\n",
            "    return asyncio_run(self.serve(sockets=sockets), loop_factory=self.config.get_loop_factory())\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/runners.py\", line 195, in run\n",
            "    return runner.run(main)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/runners.py\", line 118, in run\n",
            "    return self._loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"uvloop/loop.pyx\", line 1518, in uvloop.loop.Loop.run_until_complete\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 71, in serve\n",
            "    await self._serve(sockets)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 78, in _serve\n",
            "    config.load()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/config.py\", line 439, in load\n",
            "    self.loaded_app = import_from_string(self.app)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/importer.py\", line 19, in import_from_string\n",
            "    module = importlib.import_module(module_str)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 999, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
            "  File \"/content/api/main.py\", line 3, in <module>\n",
            "    from models import predict_rnn, predict_bert, lstm_model, gru_model\n",
            "  File \"/content/api/models.py\", line 18, in <module>\n",
            "    lstm_model.eval()\n",
            "    ^^^^^^^^^^^^^^^\n",
            "AttributeError: 'collections.OrderedDict' object has no attribute 'eval'\n",
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/uvicorn\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/click/core.py\", line 1485, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/click/core.py\", line 1406, in main\n",
            "    rv = self.invoke(ctx)\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/click/core.py\", line 1269, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/click/core.py\", line 824, in invoke\n",
            "    return callback(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/main.py\", line 424, in main\n",
            "    run(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/main.py\", line 594, in run\n",
            "    server.run()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 67, in run\n",
            "    return asyncio_run(self.serve(sockets=sockets), loop_factory=self.config.get_loop_factory())\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/runners.py\", line 195, in run\n",
            "    return runner.run(main)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/runners.py\", line 118, in run\n",
            "    return self._loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"uvloop/loop.pyx\", line 1518, in uvloop.loop.Loop.run_until_complete\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 71, in serve\n",
            "    await self._serve(sockets)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 78, in _serve\n",
            "    config.load()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/config.py\", line 439, in load\n",
            "    self.loaded_app = import_from_string(self.app)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/importer.py\", line 19, in import_from_string\n",
            "    module = importlib.import_module(module_str)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 999, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
            "  File \"/content/api/main.py\", line 3, in <module>\n",
            "    from models import predict_rnn, predict_bert, lstm_model, gru_model\n",
            "  File \"/content/api/models.py\", line 18, in <module>\n",
            "    lstm_model.eval()\n",
            "    ^^^^^^^^^^^^^^^\n",
            "AttributeError: 'collections.OrderedDict' object has no attribute 'eval'\n",
            "2026-01-20 15:42:03.964583: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2026-01-20 15:42:03.974105: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2026-01-20 15:42:04.016240: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768923724.088082   10728 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768923724.110026   10728 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768923724.166175   10728 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768923724.166269   10728 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768923724.166275   10728 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768923724.166280   10728 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-20 15:42:04.182270: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/uvicorn\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/click/core.py\", line 1485, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/click/core.py\", line 1406, in main\n",
            "    rv = self.invoke(ctx)\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/click/core.py\", line 1269, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/click/core.py\", line 824, in invoke\n",
            "    return callback(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/main.py\", line 424, in main\n",
            "    run(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/main.py\", line 594, in run\n",
            "    server.run()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 67, in run\n",
            "    return asyncio_run(self.serve(sockets=sockets), loop_factory=self.config.get_loop_factory())\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/runners.py\", line 195, in run\n",
            "    return runner.run(main)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/runners.py\", line 118, in run\n",
            "    return self._loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"uvloop/loop.pyx\", line 1518, in uvloop.loop.Loop.run_until_complete\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 71, in serve\n",
            "    await self._serve(sockets)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 78, in _serve\n",
            "    config.load()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/config.py\", line 439, in load\n",
            "    self.loaded_app = import_from_string(self.app)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/importer.py\", line 19, in import_from_string\n",
            "    module = importlib.import_module(module_str)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 999, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
            "  File \"/content/api/main.py\", line 3, in <module>\n",
            "    from models import predict_rnn, predict_bert, lstm_model, gru_model\n",
            "  File \"/content/api/models.py\", line 49, in <module>\n",
            "    lstm_model.load_state_dict(torch.load(f\"{BASE_PATH}/lstm_model.pt\", map_location=DEVICE))\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 2629, in load_state_dict\n",
            "    raise RuntimeError(\n",
            "RuntimeError: Error(s) in loading state_dict for LSTMModel:\n",
            "\tsize mismatch for embedding.weight: copying a param with shape torch.Size([20000, 128]) from checkpoint, the shape in current model is torch.Size([141052, 100]).\n",
            "\tsize mismatch for lstm.weight_ih_l0: copying a param with shape torch.Size([512, 128]) from checkpoint, the shape in current model is torch.Size([512, 100]).\n",
            "2026-01-20 15:44:48.491800: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2026-01-20 15:44:48.496576: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2026-01-20 15:44:48.510099: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768923888.532984   11405 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768923888.539579   11405 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768923888.556542   11405 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768923888.556586   11405 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768923888.556590   11405 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768923888.556593   11405 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-20 15:44:48.561702: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
            "INFO:     Started server process [11405]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adbb8f78",
        "outputId": "b621e283-63da-4886-fa9b-ceb4a403849b"
      },
      "source": [
        "#@title Test API Locally (with model selector)\n",
        "import requests\n",
        "\n",
        "API_URL = \"http://127.0.0.1:8000/predict\"\n",
        "\n",
        "email_text = \"Dear Customer,   Your bank account has been temporarily suspended due to suspicious activity.  Please click the link below to verify your account immediately:  http://verify-bank-login.com\" #@param {type:\"string\"}\n",
        "model_selector = \"bert\" #@param [\"bert\", \"lstm\", \"gru\"]\n",
        "\n",
        "payload = {\n",
        "    \"text\": email_text,\n",
        "    \"model\": model_selector\n",
        "}\n",
        "\n",
        "response = requests.post(API_URL, json=payload)\n",
        "\n",
        "print(\"Status Code:\", response.status_code)\n",
        "print(\"Response:\", response.json())"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Status Code: 200\n",
            "Response: {'model': 'bert', 'prediction': 'Phishing', 'confidence': 0.9971}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c66c97b",
        "outputId": "57a514b4-55e6-4958-a07b-e2c7449504e3"
      },
      "source": [
        "#@title Configure ngrok and Expose FastAPI\n",
        "from pyngrok import ngrok\n",
        "\n",
        "ngrok.set_auth_token(\"38WnwFCtW3YqlDfVKfl48LhxvTt_PrkYuV61TjmG624NXWW3\")\n",
        "print(\"ngrok authtoken set.\")\n",
        "\n",
        "ngrok.kill()\n",
        "\n",
        "public_url_tunnel = ngrok.connect(8000)\n",
        "print(\"Public API URL:\", public_url_tunnel.public_url)\n",
        "print(\"Swagger Docs:\", public_url_tunnel.public_url + \"/docs\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ngrok authtoken set.\n",
            "Public API URL: https://albert-unsheeting-lacteally.ngrok-free.dev\n",
            "Swagger Docs: https://albert-unsheeting-lacteally.ngrok-free.dev/docs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5db0e024",
        "outputId": "c1ee8a46-7c65-488a-a518-c6ca88dae1c8"
      },
      "source": [
        "#@title Test API via ngrok URL\n",
        "import requests\n",
        "\n",
        "# Ensure public_url_tunnel is available from the previous cell execution\n",
        "if 'public_url_tunnel' not in locals():\n",
        "    print(\"Error: ngrok tunnel not established. Please run the 'Configure ngrok and Expose FastAPI' cell first.\")\n",
        "else:\n",
        "    NGROK_API_URL = public_url_tunnel.public_url + \"/predict\"\n",
        "\n",
        "    # Use the same input parameters as the local test\n",
        "    email_text = \"Dear Customer,   Your bank account has been temporarily suspended due to suspicious activity.  Please click the link below to verify your account immediately:  http://verify-bank-login.com\" #@param {type:\"string\"}\n",
        "    model_selector = \"bert\" #@param [\"bert\", \"lstm\", \"gru\"]\n",
        "\n",
        "    payload = {\n",
        "        \"text\": email_text,\n",
        "        \"model\": model_selector\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(NGROK_API_URL, json=payload)\n",
        "        print(\"Status Code:\", response.status_code)\n",
        "        print(\"Response:\", response.json())\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error connecting to ngrok URL: {e}\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Status Code: 200\n",
            "Response: {'model': 'bert', 'prediction': 'Phishing', 'confidence': 0.9971}\n"
          ]
        }
      ]
    }
  ]
}